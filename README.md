# Rocket_Landing_Optimisation_Algorithms
Simulated annealing (SA) and Ant Colony Optimisation (ACO) both were applied to evolve a neural network controller to land simulated rockets with the goal of lowering the fitness value.

Our experiments show that both Simulated Annealing and Ant Colony Optimisation are highly capable algorithms being able to effectively tune neural network weights within the twenty thousand evaluation allotted budget. ACO manages to find close to optimal solutions converging quickly with its pheromone-guided exploration. While SA steadily explores the solution space further refining and providing a more reliable optimal solution. Statistically significant differences in final test fitness (p = 0.0286 Students t-test) confirm that SAs advantage is real.
The SA approach proved to be highly successful and more dependable than ACO method, in both the training and the test problems. Using temperature with adaptive cooling schedule, Best-of-K Neighbour Sampling and periodic Variable-Neighbourhood Descent an effective balance between exploration and refinement enabling optimal solutions while escaping local optima. ACO used Rank-based sampling, pheromone evaporation, and Gaussian sampling to effectively prevent stagnation but found itself plateauing. SA achieved a mean test fitness of half of ACO at 0.0866 and with lower significantly lower variance with a lower train-test gap showing greater generalisation. These findings underscore the SA approach delivers both more optimal and more consistent solutions than the ACO.
Future work could include upgrading of the ACO algorithm, so it more effectively competes with SA. This could be done by refining the algorithm using adaptive pheromone evaporation schedules that responds to search progress like in the SA. Dynamic ant population sizing to more effectively balance exploration and refinement and enhance the immigrant or restart systems to better escape stagnation this could all improve convergence without diminishing diversity. Finally benchmarking against other metaheuristics such as Differential Evolution or Particle Swarm Optimisation that could provide different strengths and more robust ways to find optimal solutions.
